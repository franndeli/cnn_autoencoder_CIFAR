import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from skimage.color import rgb2lab, lab2rgb
import numpy as np
import matplotlib.pyplot as plt

# Custom Dataset: converts CIFAR-10 images (RGB) to LAB and returns L and ab
class LabColorizationDataset(Dataset):
    def __init__(self, train=True):
        from torchvision.datasets import CIFAR10
        self.data = CIFAR10(root='.', train=train, download=True)
    def __len__(self):
        return len(self.data)
    def __getitem__(self, idx):
        img, _ = self.data[idx]                 # img is PIL image
        img = np.array(img) / 255.0             # to [0,1]
        lab = rgb2lab(img).astype(np.float32)   # shape (32,32,3)
        L = lab[:, :, 0]
        ab = lab[:, :, 1:]  # shape (32,32,2)
        # Normalize channels: L in [-1,1], ab in ~[-1,1]
        L = L / 50.0 - 1.0
        ab = ab / 110.0
        # To Torch tensors, shape C×H×W
        L_tensor = torch.from_numpy(L).unsqueeze(0)        # 1×32×32
        ab_tensor = torch.from_numpy(ab.transpose((2,0,1)))  # 2×32×32
        return L_tensor, ab_tensor

# Simple Convolutional Autoencoder
class ColorConvAutoencoder(nn.Module):
    def __init__(self):
        super(ColorConvAutoencoder, self).__init__()
        # Encoder: 1->64->128->256
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1),  # 32->16
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), # 16->8
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),# 8->4
            nn.ReLU(inplace=True)
        )
        # Decoder: 256->128->64->2 (with ConvTranspose for upsampling)
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 4->8
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),   # 8->16
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),    # 16->32
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 2, kernel_size=3, padding=1)                         # final 2-ch output
        )
    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

# Main training and visualization
def train_and_colorize():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    # Load datasets
    train_dataset = LabColorizationDataset(train=True)
    test_dataset  = LabColorizationDataset(train=False)
    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
    test_loader  = DataLoader(test_dataset,  batch_size=10, shuffle=False, num_workers=2)

    # Initialize model, loss, optimizer
    model = ColorConvAutoencoder().to(device)
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-3)

    # Training loop
    epochs = 10
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        for L_batch, ab_batch in train_loader:
            L_batch = L_batch.to(device)       # (B,1,32,32)
            ab_batch = ab_batch.to(device)     # (B,2,32,32)
            optimizer.zero_grad()
            ab_pred = model(L_batch)           # predict (a,b)
            loss = criterion(ab_pred, ab_batch)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * L_batch.size(0)
        epoch_loss = running_loss / len(train_loader.dataset)
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}")

    # Visualization on test images
    model.eval()
    dataiter = iter(test_loader)
    L_test, ab_test = next(dataiter)  # get first batch (10 images)
    with torch.no_grad():
        L_test = L_test.to(device)
        ab_pred = model(L_test).cpu()

    # Prepare figure: 3 columns (Grayscale, True, Predicted) for first 4 images
    num_images = 4
    fig, axes = plt.subplots(num_images, 3, figsize=(8, 2*num_images))
    for i in range(num_images):
        # Denormalize L channel to [0,100]
        L_norm = L_test[i].cpu().numpy().squeeze()            # shape (32,32)
        L_real = (L_norm + 1.0) * 50.0                        # back to 0-100
        # Prepare grayscale (replicate L over RGB by lab2rgb with zeros ab)
        lab_gray = np.zeros((32,32,3), dtype=np.float32)
        lab_gray[...,0] = L_real
        rgb_gray = lab2rgb(lab_gray)  # grayscale image

        # Ground-truth color
        ab_real = ab_test[i].numpy().transpose((1,2,0)) * 110.0  # shape (32,32,2)
        lab_true = np.zeros((32,32,3), dtype=np.float32)
        lab_true[...,0] = L_real
        lab_true[...,1:] = ab_real
        rgb_true = lab2rgb(lab_true)

        # Predicted color
        ab_pred_np = ab_pred[i].numpy().transpose((1,2,0)) * 110.0
        lab_pred = np.zeros((32,32,3), dtype=np.float32)
        lab_pred[...,0] = L_real
        lab_pred[...,1:] = ab_pred_np
        rgb_pred = lab2rgb(lab_pred)

        # Plot images
        ax0, ax1, ax2 = axes[i]
        ax0.imshow(rgb_gray); ax0.set_title('Input (L*)'); ax0.axis('off')
        ax1.imshow(rgb_true); ax1.set_title('Ground Truth'); ax1.axis('off')
        ax2.imshow(rgb_pred); ax2.set_title('Predicted'); ax2.axis('off')

    plt.tight_layout()
    plt.savefig('colorization_results.png')
    print("Saved colorization_results.png (grayscale vs true vs predicted)")

if __name__ == '__main__':
    train_and_colorize()
